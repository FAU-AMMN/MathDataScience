\chapter{Integralrechnung}
\label{\detokenize{integration/integration:integralrechnung}}\label{\detokenize{integration/integration::doc}}
Im Folgenden wollen wir uns mit der Integration von Funktionen \(f:[a,b] \rightarrow \R\) beschäftigen. Für nichtnegative Funktionen soll das Integral intuitiv der Fläche unter der Funktion entsprechen, für allgemeinere Funktionen wollen wir die Differenz aus der Flächen definiert durch den positiven und negativen Teil der Funktion (den wir später noch genau definieren werden).  Um eine Fläche zu approximieren, können wir eine Zerlegung in Rechtecke verwenden, deren Fläche wir elementar als Produkt der Seitenlängen erhalten. Die Rechtecksseiten legen wir parallel zu den Koordinatenachsen, d.h. die erste Seite ist ein Abstand der Argumente, die zweite Seite entspricht im wesentlichen einem Funktionswert.
Wir führen dazu Zerlegungen
\begin{equation*}
 a = t_0 < t_1 < \ldots < t_n = b
\end{equation*}
ein, und schreiben \(T=\{t_0,\ldots,t_n\}\). Die Menge der Zerlegungen eines Intervalls ist gegeben durch
\begin{equation*}
 {\mathcal E} = \{ T \subset [a,b]~|~ a,b \in T, \vert T \vert < \infty\}.
\end{equation*}
Eine Zerlegung \(T\) heißt feiner als \(T'\), wenn \(T' \subset T\). Wir denken uns \(T\) identifiziert mit den Teilintervallen \([t_i,t_{i+1}]\), \(i=0,\ldots,n-1\). Diese werden wir als erste Seiten der Rechtecke verwenden, die zweite erhalten wir aus den Funktionswerten. Der klassische Ansatz zum Riemann Integral ist es dabei zwei Rechtecke zu verwenden, ein möglichst großes und ein möglichst kleines (intuitiv mit dem maximalen und dem minimalen Funktionswert in \([t_i,t_{i+1}]\)). Rechnen wir dazu (mit Vorzeichen) die Summe der Rechtecksflächen aus, dann erhalten wir die sogenannten Ober  und Untersummen
\begin{align*}
O(f,T) &= \sum_{i=0}^{n-1} (t_{i+1} - t_i) S_i(f) &S_i(f) =  \sup_{t \in  [t_i,t_{i+1}]} f(t), \\
U(f,T) &= \sum_{i=0}^{n-1} (t_{i+1} - t_i) s_i(f) &s_i(f) =  \inf_{t \in  [t_i,t_{i+1}]} f(t).
\end{align*}
Aus der Definition ist klar, dass \(s_i \leq S_i\) und damit
\begin{equation*}
 U(f,T) \leq O(f,T) \qquad \forall T \in {\mathcal E}.
\end{equation*}
Wir beachten, dass im Fall einer stetigen Funktion, bei der im kompakten Intervall \([t_i,t_{i+1}]\) ja immer Minimum und Maximum existieren, auch wirklich
\begin{equation*}
 S_i(f) =  \max_{t \in  [t_i,t_{i+1}]} f(t), \qquad s_i(f) =  \min_{t \in  [t_i,t_{i+1}]} f(t)
\end{equation*}
gilt, d.h. wir bilden wirklich Rechtecke mit dem größten bzw. kleinsten Funktionswert. Die Definition mit Supremum und Infimum ist aber auch für nichtstetige Funktionen geeignet.
\label{integration/integration:example-0}
\begin{example}{}{}



Sei \(f:[-1,1] \rightarrow \R\) die Heaviside Funktion, d.h. \(f(x) =1 \) für \(x \geq 0\) and \(f(x) = 0\) für \(x < 0\). Hier können wir die Fläche unter der Funktion direkt als Rechteck berechnen und erhalten also \(1\) als korrekten Wert des Integrals.
Sei \(k\) der maximale Index, sodass \(t_k < 0\). Dann gilt
\begin{equation*}
  O(f,T) = \sum_{i=k}^{n-1} (t_{i+1} - t_i) = 1 - t_k, \qquad U(f,T) = \sum_{i=k+1}^{n-1} (t_{i+1} - t_i) = 1 - t_{k+1}.\end{equation*}
Damit sehen wir
\begin{equation*}
 U(f,T) \leq 1 \leq O(f,T).
\end{equation*}
Andererseits kann \(O(f,T)\) beliebig nahe an \(1\) kommen, wenn \(t_k\) nahe genug bei \(0\) liegt, während \(U(f,T)\) sogar exakt gleich \(1\) ist, wenn \(t_{k+1} = 0\) gilt. Also ist das Integral der größtmögliche Wert der Untersummen bei allen möglichen Zerlegungen \(T\) und das Infimum der Obersummen aller möglichen Zerlegungen. Dies werden wir später als Definition verwenden.
\end{example}
\label{integration/integration:lemma-1}
\begin{lemma}{}{}



Die Unter  und Obersummen einer Funktion \(f\) haben die folgenden Eigenschaften:
\begin{itemize}
\item {} 
\(i)\) \(\forall T \in {\mathcal E}: U(-f,T) = - O(f,T)\).

\item {} 
\(ii)\) \(\forall T \in {\mathcal E}, c \geq 0: U(cf,T) = c U(f,T)\) und \(O(cf,T) = c O(f,T).\)

\item {} 
\(iii)\) \(\forall T' \subset T \in {\cal E}: U(f,T) \geq U(f,T')\) und \(O(f,T) \leq O(f,T')\).

\item {} 
\(iv)\) \(\forall T, T' \in {\mathcal E}: U(f,T) \leq O(f,T')\)

\item {} 
\(v)\) Für eine weitere Funktion \(g\) gilt

\end{itemize}
\begin{equation*}
\forall T \in {\mathcal E}: U(f+g,T) \geq U(f,T) + U(g,T), \quad O(f+g,T) \leq O(f,T) + O(g,T).
\end{equation*}\end{lemma}

\begin{emphBox}{}{}
Proof. \textbf{Ad \(i)\):}

Folgt direkt aus
\begin{equation*}
\inf_{t \in [t_i,t_{i+1}]}(-f(t)) = - \sup_{t \in [t_i,t_{i+1}]}(f(t))
\end{equation*}
\textbf{Ad \(ii)\):}

Gilt wegen
\begin{equation*}
 \inf_{t \in [t_i,t_{i+1}]} (c f(t)) = c \inf_{t \in [t_i,t_{i+1}]} f(t) \qquad \sup_{t \in [t_i,t_{i+1}]} (c f(t)) = c \sup_{t \in [t_i,t_{i+1}]} f(t).
\end{equation*}
\textbf{Ad \(iii)\):}

Gilt \(T' \subset T\), dann gibt es für jedes \(i\) ein \(j(i)\) mit \(t_i' =t_{j(i)}\). Damit folgt
\begin{align*} O(f,T') &= \sum_{i=0}^{n'-1} (t_{i+1}' - t_i') \sup_{t \in  [t_i',t_{i+1}']} f(t) =\sum_{i=0}^{n'-1} (t_{j(i+1)} - t_{j(i)}) \sup_{t \in  [t_{j(i)},t_{j(i+1)}]} f(t) \\
&= \sum_{i=0}^{n'-1} \sum_{k=j(i)}^{j(i+1)-1} (t_{k+1} - t_{k}) \sup_{t \in  [t_{j(i)},t_{j(i+1)}]} f(t)  \\
&\geq \sum_{i=0}^{n'-1} \sum_{k=j(i)}^{j(i+1)-1} (t_{k+1} - t_{k}) \sup_{t \in  [t_{k},t_{k+1}]} f(t)   =\sum_{i=0}^{n-1} (t_{k+1} - t_{k}) \sup_{t \in  [t_{k},t_{k+1}]} f(t)  \\ &= O(f,T).
\end{align*}
Der Beweis für Untersummen ist analog.

\textbf{Ad \(iv)\):}

Sei \(T''= T \cup T'\). Dann ist klarerweise \(U(f,T'') \leq O(f,T'')\) und mit \(iii)\) folgt
\begin{equation*}
 U(f,T') \leq U(f,T'') \leq O(f,T'') \leq O(f,T) .
\end{equation*}
\textbf{Ad \(v)\):}
Folgt aus
\begin{equation*}
 \inf (f+g) \geq \inf f + \inf g, \qquad \sup (f+g) \geq \sup f + \sup g.  \square
\end{equation*}\end{emphBox}


\section{Riemann Integral}
\label{\detokenize{integration/riemann:riemann-integral}}\label{\detokenize{integration/riemann::doc}}
Da die Obersummen mit feiner werdender Zerlegung kleiner und die Untersummen größer werden, ist es naheliegend im Grenzwert auf die kleinsten Ober  bzw. größten Untersummen zu schauen. Diese existieren nicht unbedingt, aber zumindest das Infimum bzw. Supremum.
\label{integration/riemann:definition-0}
\begin{definition}{}{}



Sei \(f:[a,b] \rightarrow \R\) beschränkt. Dann heißt
\begin{equation*}
 O(f) = \inf\{ O(f,T)~|~ T \in {\cal E} \}\end{equation*}
Oberintegral und
\begin{equation*}
 U(f) =  \sup\{ U(f,T)~|~ T \in {\cal E} \}\end{equation*}
Unterintegral.
Gilt \(O(f) = U(f)\), dann heißt \(f\) integrierbar (im Sinn von Riemann) und man nennt
\begin{equation*}
 \int_a^b f(x)~dx := O(f) = U(f)
\end{equation*}
das Integral von \(f\) im Intervall \([a,b]\).
\end{definition}

\begin{emphBox}{Bernhard Riemann}{}

\href{https://de.wikipedia.org/wiki/Bernhard\_Riemann}{Georg Friedrich Bernhard Riemann} (* 17. September 1826 in Breselenz bei Dannenberg (Elbe); † 20. Juli 1866 in Selasca bei Verbania am Lago Maggiore) war ein deutscher Mathematiker.
\end{emphBox}

Im obigen Beispiel der Heaviside Funktion sehen wir sofort \(O(f)=U(f)=1\) und damit die Integrierbarkeit und
\(\int_{-1}^1 f(x)~dx = 1\).
Wir beachten, dass allgemein bei einer beschränkten Funktion gilt
\begin{equation*}
O(f) \leq (b-a) \sup_{t \in [a,b]}f(t) \leq  (b-a) \sup_{t \in [a,b]} \vert f(t) \vert
\end{equation*}
und
\begin{equation*}
U(f) \geq (b-a) \inf_{t \in [a,b]}f(t) \leq -  (b-a) \sup_{t \in [a,b]} \vert f(t) \vert .
\end{equation*}
Darüber hinaus gilt wegen der Eigenschaft \(U(f,T') \leq O(f,T)\) für alle \(T,T'\) auch \(U(f) \leq O(f)\).
\label{integration/riemann:example-1}
\begin{example}{}{}



Sei \(f:[0,1] \rightarrow \R\) definiert durch \(f(x) =1\) für \(x\in \Q\) und \(f(x)=0\) für \(x \notin \Q\). Dann ist bei jeder Zerlegung \(\sup_{t \in [t_i,t_{i+1}]}(f(t)) =1\) und \(\inf_{t \in [t_i,t_{i+1}]}(f(t))=0\), da jedes Teilintervall sowohl reelle als auch rationale Zahlen enthält. Damit ist auch \(O(f)=1\) und \(U(f) =0\), die Funktion ist also nicht integrierbar.
\end{example}

Wir haben gesehen, dass Ober  und Untersummen einige Eigenschaften nahe an der Linearität erfüllen. Diese ist im Grenzwert des Integrals dann gegeben:
\label{integration/riemann:lemma-2}
\begin{lemma}{}{}



Sei \({\cal I}\) die Menge der integrierbaren Funktionen auf dem Intervall \([a,b]\). dann ist \({\cal I}\) ein Vektorraum. Die Abbildung
\begin{equation*}
I: {\cal I} \rightarrow \R, f \mapsto \int_a^b f(x)~dx
\end{equation*}
ist linear, d.h.,
\begin{equation*}
 \int_a^b (f(x)+g(x))~dx = \int_a^b f(x)~dx + \int_a^b g(x)~dx,
\end{equation*}
und
\begin{equation*}
 \int_a^b c f(x)~dx = c \int_a^b f(x)~dx
\end{equation*}
für alle \(c \in \R\). Darüber hinaus ist die Abbildung \(I\) monoton, d.h. falls \(f \geq g\) (d.h. \(f(x) \geq g(x)\) für alle \(x\in[a,b]\)) gilt, dann folgt \(\int_a^b f(x)~dx \geq \int_a^b g(x)~dx. \)
\end{lemma}

\begin{emphBox}{}{}
Proof. Wie benutzen die Eigenschaften der Unter  und Obersummen und erhalten
\begin{equation*}
 U(f,T') + U(g,T') \leq U(f+g,T') \leq O(f+g,T) \leq O(f,T) + O(g,T) .
\end{equation*}
Mit der Integrierbarkeit von \(f\) und \(g\) folgt daraus
\begin{equation*}
 \int_a^b f(x)~dx + \int_a^b g(x)~dx \leq U(f+g) \leq O(f+g) \leq \int_a^b f(x)~dx + \int_a^b g(x)~dx.
\end{equation*}
Damit ist
\begin{equation*}
 U(f+g) = O(f+g) = \int_a^b f(x)~dx + \int_a^b g(x)~dx,
\end{equation*}
also ist \(f+g\) integrierbar und es gilt die gewünschte Eigenschaft für die Summe.
Ist \(c \geq 0\), dann wissen wir für alle Zerlegungen
\( U(cf,T) = c U(f,T)\), also auch \(U(cf) = c U(f)\). Analog folgt \(O(cf) = c O(f)\) und damit für integrierbare \(f\) auch die
Integrierbarkeit von \(c f\) mit
\begin{equation*}
  \int_a^b c f(x)~dx = U(cf) = O(cf) = c  \int_a^b f(x)~dx.
\end{equation*}
Ist \(c \leq 0\), dann benutzen wir
\begin{equation*}
 U(cf,T) = U(-(-c)f,T) = _- O((-c)f,T) = - (-c) O(f,T) = c O(f,T)
\end{equation*}
und analog \(O(cf,T) = c U(f,T)\). Damit folgern wir
\begin{equation*}
 U(cf) = \inf_T U(cf,T) = \inf_T (c O(f,T)) = c \sup_T O(f,t) = c \int_a^b f(x)~dx
\end{equation*}
und analog \(O(cf) = \int_a^b f(x)~dx \). Also ist \(cf\) integrierbar und es gilt
\begin{equation*}
  \int_a^b c f(x)~dx = c \int_a^b f(x)~dx.
\end{equation*}
Für die Monotonie genügt wegen der Linearität zu zeigen, dass \(\int_a^b f(x)~dx \geq 0\) für nichtnegative Funktionen \(f\) gilt. Dies folgt aber direkt aus \(U(f,T) \geq 0\) für alle \(T\). \(\square\)
\end{emphBox}

Wir haben vorher schon angekündigt, dass wir das Integral als Differenz der Flächen unter positivem und negativem Teil der Funktion sehen wollen. Um dies präziser zu machen definieren wir
\begin{equation*}
 f_+(x) = \begin{pmatrix} f(x) & f(x) \geq 0 \\ 0 & \text{sonst} \end{pmatrix}.
\end{equation*}
und
\begin{equation*}
  f_-(x) = \begin{pmatrix}-f(x) & f(x) \leq 0 \\ 0 & \text{sonst} \end{pmatrix}.
\end{equation*}
Dann ist \(f = f_+ - f_-\) und \(|f|=f_+ + f_-\). Man kann zeigen, dass die Integrierbarkeit von \(f\) äquivalent zur Integrierbarkeit von \(f_+\) und \(f_-\) ist und es gilt wegen der Linearität auch
\begin{equation*}
 \int_a^b f(x)~dx = \int_a^b f_+(x)~dx - \int_a^b f_-(x)~dx.
\end{equation*}
Eine weitere interessante Eigenschaft, die wir hier ohne Beweis angeben, ist die Additivität des Integrals bezüglich Teilintervallen: Sei \(f\) auf \([a,c]\) integrierbar und \(b \in (a,c)\), dann sind die Einschränkungen von \(f\) auch auf \([a,b]\) und \([b,c]\) integrierbar und es gilt
\begin{equation*}
 \int_a^c f(x)~dx =  \int_a^b f(x)~dx + \int_b^c f(x)~dx .
\end{equation*}
Wir haben bisher die Klasse der integrierbaren Funktionen eingeführt und wenige Beispiele kennen gelernt. Der folgende Satz zeigt, dass diese Klasse sehr viele Funktionen enthält:
\label{integration/riemann:theorem-3}
\begin{theorem}{}{}



Sei \(f:[a,b] \rightarrow \R\) stetig. Dann ist \(f\) integrierbar.
\end{theorem}

\begin{emphBox}{}{}
Proof.  \(f\) ist stetig, damit auf dem kompakten Intervall \([a,b]\) sogar gleichmäßig stetig. Also gibt es für jedes \(\epsilon >0 \) ein \(\delta > 0\), sodass für alle \(x,y\) mit \(|x-y| < \delta\) gilt:
\begin{equation*}
 \vert f(x) - f(y) \vert < \frac{\epsilon}{b-a}.
\end{equation*}
Sei \(t_i = a + \frac{b-a}{n} i\) mit \(n > \frac{b-a}\delta\). Dann gilt für alle \(x,y \in [t_i,t_{i+1}]\) auch \(|x-y| < \delta\), somit folgt
\(S_i - s_i < \frac{\epsilon}{b-a}\). Also erhalten wir
\begin{equation*}
 0 \leq O(f,T) - U(f,T) = \sum_{i=0}^{n-1} (t_{i+1}-t_i)(S_i-s_i) < \sum_{i=0}^{n-1} \frac{b-a}{n} ~ \frac{\epsilon}{b-a} = \epsilon.
\end{equation*}
Daraus folgern wir dann auch \(O(f) = U(f)\), also ist \(f\) integrierbar. \(\square\)
\end{emphBox}


\section{Der Hauptsatz der Differential  und Integralrechnung}
\label{\detokenize{integration/hdi:der-hauptsatz-der-differential-und-integralrechnung}}\label{\detokenize{integration/hdi::doc}}
Nun wollen wir uns noch mit dem Zusammenhang zwischen Differential  und Integralrechnung beschäftigen. Wir betrachten dazu lokal integrierbare Funktionen \(f:[a,b] \rightarrow \R\), d.h. Funktionen, die auf jedem Teilintervall von \([a,b]\) integrierbar sind.

Wir nennen \(F:[a,b] \rightarrow \R\) unbestimmtes Integral von \(f\), wenn für \(y,z \in [a,b]\) gilt
\begin{equation*}
 F(z) - F(y) = \int_y^z f(x)~dx.
\end{equation*}
(Wir beachten, dass wir zur Konsistenz ein Integral mit vertauschten Integralgrenzen mit negativem Vorzeichen definieren, d.h.
\(\int_z^y f(x)~dx = - \int_y^z f(x)~dx. \))

Wir nennen \(F:[a,b] \rightarrow \R\) Stammfunktion von \(f\), wenn \(F'(x)=f(x)\) für alle \(x \in [a,b]\) gilt. Der Inhalt des Hauptsatzes der Integralrechnung ist es zu zeigen, dass die Konzepte Stammfunktion und unbestimmtes Integral auf das Gleiche führen, d.h. die Integration ist damit die Umkehrung der Differentiation.
Zunächst wollen wir einige Resultate über Stammfunktionen herleiten:
\label{integration/hdi:lemma-0}
\begin{lemma}{}{}



Sei \(F\) eine Stammfunktion von \(f\), dann ist \(G\) genau dann Stammfunktion, wenn \(F-G\) konstant ist.
\end{lemma}

\begin{emphBox}{}{}
Proof. Ist \(G\) eine Stammfunktion, dann gilt \((F-G)'=F'-G'= f-f=0\) überall in \([a,b]\). Wenden wir den Mittelwertsatz der Differentialrechnung an, so folgt für alle \(y,z\) und ein \(x \in (y,z)\)
\begin{equation*}
 \frac{(F-G)(z) - (F-G)(y)}{z-y} = (F-G)'(x) = 0.
\end{equation*}
Also ist \((F-G)(z) = (F-G)(y)\) für alle \(y,z \in  [a,b]\), d.h. \(F-G\) ist konstant.
Ist umgekehrt \(F-G\) konstant, dann folgt sofort \(G' = F' + (G-F)' = F'=f\), also ist \(G\) Stammfunktion. \(\square\)
\end{emphBox}
\label{integration/hdi:lemma-1}
\begin{lemma}{}{}



Sei \(f:[a,b]\rightarrow \R\) beschränkt und \(F\) Stammfunktion oder unbestimmtes Integral. Dann ist \(F\) Lipschitz stetig mit Konstante \(L=\sup_{x \in [a,b]} \vert f(x) \vert. \)
\end{lemma}

\begin{emphBox}{}{}
Proof. Wir haben aus den Abschätzungen für Unter  und Obersummen schon gesehen, das
\begin{equation*}
 \vert \int_y^z f(x)~dx \vert \leq \vert z -y \vert ~\sup_{x \in [a,b]} \vert f(x) \vert
\end{equation*}
gilt, also folgt die Aussage für ein unbestimmtes Integral. Ist \(F\) Stammfunktion, so impliziert der Mittelwertsatz
\begin{equation*}
 \vert F(y) - F(z) \vert = \vert y - z \vert ~\vert f(x) \vert,
\end{equation*}
für ein \(x \in (y,z)\) und die letzte Term ist kleiner als das Supremum. \(\square\).
\end{emphBox}

Ein wichtiges Resultat, ähnlich bei der Differentiation, ist der Mittelwertsatz der Integralrechnung:
\label{integration/hdi:theorem-2}
\begin{theorem}{}{}



Sei \(f\) stetig auf \([a,b]\) und \(y,z \in [a,b]\), \(y < z\). Dann gibt es ein \(x_0 \in (y,z)\) mit
\begin{equation*}
 f(x_0) = \frac{\int_y^z f(x)~dx}{z-y}.
\end{equation*}\end{theorem}

\begin{emphBox}{}{}
Proof. \(f\) ist eine stetige Funktion auf dem kompakten Intervall \([y,z]\), nimmt dort also sein Maximum und Minimum an. Damit gibt es
\begin{equation*}
 f(x_-) = \min_{x \in [y,z]} f(x) \leq \frac{\int_y^z f(x)~dx}{z-y} \leq  \max_{x \in [y,z]} f(x) = f(x_+).
\end{equation*}
Nach dem Zwischenwertsatz für stetige Funktionen gibt es also ein \(x_0\) zwischen \(x_+\) und \(x_-\) mit
\begin{equation*}
 f(x_0) = \frac{\int_y^z f(x)~dx}{z-y}. \square
\end{equation*}\end{emphBox}

Nun können wir den wichtigsten Satz zum Zusammenhang zwischen Differentiation und Integration beweisen, den Hauptsatz der Differential  und Integralrechnung:
\label{integration/hdi:theorem-3}
\begin{theorem}{}{}



Sei \(f:[a,b] \rightarrow \R\) stetig. Dann ist\(F_a: [a,b] \rightarrow \R, x \mapsto \int_a^x f(y)~dy\)
eine Stammfunktion. Eine Funktion \(F:[a,b] \rightarrow \R\) ist genau dann Stammfunktion von \(f\), wenn \(F\) ein unbestimmtes Integral ist.
\end{theorem}

\begin{emphBox}{}{}
Proof. Es gilt nach dem Mittelwertsatz
\begin{equation*}
 \frac{F_a(x)-F_a(x_0)}{x-x_0} = \frac{\int_{x_0}^x f(y)~dy }{x-x_0} = f(\xi(x))
\end{equation*}
für ein \(\xi(x)\) zwischen \(x\) und \(x_0\). Damit folgt für den Grenzwert
\begin{equation*}
 F_a'(x_0) = \lim_{x\rightarrow x_0}\frac{F_a(x)-F_a(x_0)}{x-x_0} =  \lim_{x\rightarrow x_0}f(\xi(x)) = f(x_0),
\end{equation*}
da \(f\) stetig ist und \(\xi(x) \rightarrow x_0\) für \(x \rightarrow x_0\). Also ist \(F_a\) Stammfunktion.
Analog zeigt man für jedes unbestimmte Integral \(F\), dass \(F'=f\) gilt.
Sei umgekehrt \(F\) Stammfunktion, dann wissen wir, dass \(F-F_a\) konstant ist und damit
\begin{equation*}
 F(z) - F(y) = F_a(z) - F_a(y) = \int_y^z f(y)~dy,
\end{equation*}
also ist \(F\) auch unbestimmtes Integral. \(\square\)
\end{emphBox}

Wir sehen also, dass die Begriffe des unbestimmten Integrals und der Stammfunktionen übereinstimmen. Deshalb sprechen wir im Folgenden nur noch von Stammfunktionen. Bei Funktionen \(f\), von denen wir bereits wissen, dass sie die Ableitung einer Funktion \(F\) sind, können wir also den Hauptsatz der Differential  und Integralrechnung benutzen, um bestimmte Integrale zu berechnen, es gilt ja
\begin{equation*}
 \int_a^b f(x)~dx = F(b) - F(a) =: F\vert_a^b.
\end{equation*}\label{integration/hdi:example-4}
\begin{example}{}{}



Wir wissen das die Exponentialfunktion die Ableitung der Exponentialfunktion ist, also gilt
\begin{equation*}
 \int_a^b e^x ~dx = e^x\vert_a^b = e^b -e^a.
\end{equation*}
Allgemeiner ist \(e^{cx}\) die Ableitung von \(\frac{1}c e^{cx}\), als
\begin{equation*}
 \int_a^b e^{cx} ~dx =\frac{1}c (e^{cx})\vert_a^b = \frac{1}c (e^{cb} -e^{ca}).
\end{equation*}\end{example}

Das letzte Beispiel können wir folgendermaßen verallgemeinern: Ist \(f\) die Ableitung von \(F\), dann ist\(x \mapsto f(c x)\) die Ableitung von \(x\mapsto \frac{1}c F(cx)\), als
\begin{equation*}
 \int_a^b f(cx)~dx = \frac{1}c (F(cb) - F(ca)).
\end{equation*}\label{integration/hdi:example-5}
\begin{example}{}{}



Sei \(f(x) = x^m\), dann ist \(F(x) = \frac{x^{m+1}}{m+1}\) Stammfunktion.
\begin{equation*}
 \int_a^b x^m ~dx =\frac{1}{m+1}  (b^{m+1} -a^{m+1}).
\end{equation*}
Im Fall \(m=0\) erhalten wir als Integral \(b-a\), also genau die Rechtecksfläche,im Fall \(m=1\) ist das Integral \(\frac{1}2 (b^2-a^2) = \frac{1}2 (b-a)(b+a)\) die Dreiecksfläche.
\end{example}

Mit Hilfe von Differentiationsregeln können wir auch weitere Integrationsregeln erhalten. Die wahrscheinlich
wichtigste ist dabei die \{\textbackslash{}em partielle Integration\}, die wir aus der Produktregel erhalten:
\label{integration/hdi:theorem-6}
\begin{theorem}{}{}



Seien \(f:[a,b] \rightarrow \R\), \(g:[a,b] \rightarrow \R\) stetig differenzierbar. Dann gilt
\begin{equation*}
 \int_a^b f(x) g'(x) ~dx = - \int_a^b f'(x) g(x)~dx + (fg)\vert_a^b.
\end{equation*}\end{theorem}

\begin{emphBox}{}{}
Proof. Aus der Produktregel und dem Hauptsatz der Differential  und Integralrechnung folgt
\begin{equation*}
 (fg)\vert_a^b = \int_a^b (fg)'(x)~dx = \int_a^b (f'(x)g(x) + f(x)g'(x))~dx.
\end{equation*}\end{emphBox}


\section{Vertauschung von Integralen und Taylor Formel}
\label{\detokenize{integration/vertauschen:vertauschung-von-integralen-und-taylor-formel}}\label{\detokenize{integration/vertauschen::doc}}
Oft integriert man eine Funktion mehrmals, d.h. man hat eigentlich ein weiteres Integral der Stammfunktion. Wir wollen hier eine Formel für die zweifache Integration herleiten. Sei \(F\) Stammfunktion von \(f\), dann gilt
\begin{equation*}
 \int_a^b (F(x) - F(a))~dx = \int_a^b \int_a^x f(y)~dy~dx.
\end{equation*}
Intuitiv integrieren wir hier über das Dreieck \(0 \leq y \leq x \leq b\), also erwarten wir
\begin{equation*}
 \int_a^b \int_a^x f(y)~dy = \int_a^b \int_y^b f(y)~dy = \int_a^b f(y) (b-y)~dy.
\end{equation*}
Um die Gleichheit nachzuweisen, können wir partielle Integration verwenden, mit der Stammfunktion \(F_a\) wie oben und \(g(x) = b-x\) erhalten wir, da \(g'(x)=-1\), \(F_a(a) = 0 \) und \(g(b) =0\),
\begin{equation*}
 \int_a^b f(y) (b-y)~dy = - \int_a^b F_a(y) (-1)~dy = \int_a^b F_a(x)~dx =  \int_a^b \int_a^x f(x)~dx .
\end{equation*}
Eine Anwendung ist die bessere Charakterisierung von Restgliedern bei der Differentialrechnung. Sei \(f\) eine in \([a,b]\) stetig differenzierbare Funktion, dann gilt für \(x,x_0 \in [a,b]\)
\begin{align*}
f(x) - f(x_0) &= \int_{x_0}^x f'(y)~dy =  \int_{x_0}^x (f'(x_0) + f'(y) -f'(x_0))~dy \\
&= f'(x_0) (x-x_0) + \int_{x_0}^x ( f'(y) -f'(x_0))~dy \\&= f'(x_0) (x-x_0) + \int_{x_0}^x \frac{y-x_0}{x-x_0} \frac{ f'(y) -f'(x_0))}{y-x_0}~dy  (x-x_0) .
\end{align*}
Also ist das Restglied
\begin{equation*}
R(x) = \int_{x_0}^x \frac{y-x_0}{x-x_0} \frac{ f'(y) -f'(x_0))}{y-x_0}~dy .
\end{equation*}
Ist \(f\) zweimal stetig differenzierbar, dann können wir den Mittelwertsatz auf \(f'\) anwenden und erhalten
\begin{equation*}
 R(x) = \int_{x_0}^x \frac{y-x_0}{x-x_0} f''(\xi(y))~dy,
\end{equation*}
damit auch
\begin{equation*}
 |R(x)| \leq  \int_{x_0}^x \frac{y-x_0}{x-x_0} \sup_{z \in (x_0,x)} |f''(z)|~dy = \sup_{z \in (x_0,x)} |f''(z)| ~ \frac{|x-x_0|}2.
\end{equation*}





\renewcommand{\indexname}{Proof Index}


\renewcommand{\indexname}{Index}

\end{document}